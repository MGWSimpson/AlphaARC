{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e5a6c9",
   "metadata": {},
   "source": [
    "# Program Completer Tests\n",
    "\n",
    "Notebook for playing around with my program completer code and ensuring it behaves as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cdbd4",
   "metadata": {},
   "source": [
    "## Rigorous Test\n",
    "\n",
    "The following code serves as proof that our completion engine can solve all tasks. In essenece, if it can solve every training task, then it should in theory have no bugs (in theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97a05b5b\n",
      "[]\n",
      "'x48 = paint(x3, x43)\\nO = identity(asindices)'\n",
      "'x48 = paint(x3, x47)\\n'\n"
     ]
    }
   ],
   "source": [
    "from alphaarc.program_completer import ProgramCompleter\n",
    "from alphaarc.augment.program_sampler import ProgramSampler\n",
    "from alphaarc.task import Task, from_dict\n",
    "import json\n",
    "import os\n",
    "import difflib\n",
    "import time \n",
    "\n",
    "def best_completion(ground_truth, wip, completions):\n",
    "    def matching_prefix_length(a, b):\n",
    "        \"\"\"Returns number of characters that match from start of both strings.\"\"\"\n",
    "        i = 0\n",
    "        while i < len(a) and i < len(b) and a[i] == b[i]:\n",
    "            i += 1\n",
    "        return i\n",
    "\n",
    "    best = None\n",
    "    best_score = -1\n",
    "\n",
    "    for comp in completions:\n",
    "        candidate = wip + comp\n",
    "        score = matching_prefix_length(candidate, ground_truth)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = comp\n",
    "\n",
    "    return best\n",
    "\n",
    "def format_as_dummy_program(program_lines):\n",
    "    return f\"\"\"def solve_28bf18c6(I):\n",
    "    {program_lines}\"\"\"\n",
    "\n",
    "def load_tasks_from_folders(dir_path):\n",
    "        tasks = []\n",
    "        file_paths = [os.path.join(dir_path, f) for f in os.listdir(dir_path)]\n",
    "        new_tasks = [Task.from_json(path, False) for path in file_paths]\n",
    "        tasks.extend(new_tasks)\n",
    "        return tasks\n",
    "\n",
    "\n",
    "\n",
    "def complete_full_program(task, completer: ProgramCompleter): \n",
    "    prog_text = \"\"\n",
    "\n",
    "    ground_truth_text = task.program_lines\n",
    "    lines = ground_truth_text.split(\"\\n\")\n",
    "    lines = [x + \"\\n\" for x in lines[:-1]]\n",
    "\n",
    "    for i, true_line in enumerate(lines):\n",
    "        line_text = \"\"\n",
    "        while line_text != true_line:\n",
    "            \n",
    "\n",
    "            completions = completer.complete(format_as_dummy_program(prog_text + line_text), task.training_examples[0]['input'])\n",
    "            \n",
    "            best_comp = best_completion(true_line, line_text, completions)\n",
    "\n",
    "            if best_comp == None:\n",
    "                 print(completions)\n",
    "                 print(repr( line_text))\n",
    "                 print(repr(true_line))\n",
    "                 return\n",
    "            line_text += best_comp\n",
    "            \n",
    "\n",
    "        prog_text += line_text\n",
    "\n",
    "tasks = load_tasks_from_folders('../data/training/')\n",
    "sampler   = ProgramSampler(data_path=\"../data/\")\n",
    "completer = ProgramCompleter(sampler)\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    print(task.task_key)\n",
    "    if i != 66: # we skip this as it takes quite a long time to eval.\n",
    "        complete_full_program(task, completer)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0ec74",
   "metadata": {},
   "source": [
    "## Small Tests To Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0bed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphaarc.program_completer import ProgramCompleter\n",
    "from alphaarc.augment.program_sampler import ProgramSampler\n",
    "from alphaarc.task import Task\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler   = ProgramSampler(data_path=\"../data/\")\n",
    "completer = ProgramCompleter(sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a438367d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O =', 'x1 =']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_as_dummy_program(program_lines):\n",
    "    return f\"\"\"def solve_28bf18c6(I):\n",
    "    {program_lines}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "program_lines = \"\"\"\"\"\"\n",
    "\n",
    "task = Task.from_json('../data/training/dc1df850.json')\n",
    "\n",
    "\n",
    "completer.complete(format_as_dummy_program(program_lines),  task.training_examples[0]['input'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaARC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

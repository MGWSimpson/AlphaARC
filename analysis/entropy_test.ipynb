{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ffe81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, tqdm, pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from alphaarc.task import Task\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba4fc191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6150a2bd',\n",
       " 'c8f0f002',\n",
       " '68b16354',\n",
       " 'c9e6f938',\n",
       " '6fa7a44f',\n",
       " 'ac0a08a4',\n",
       " '4258a5f9',\n",
       " '9ecd008a',\n",
       " '25ff71a9',\n",
       " '3af2c5a8',\n",
       " '67e8384a',\n",
       " '56ff96f3',\n",
       " 'dc1df850',\n",
       " 'ae4f1146',\n",
       " 'aabf363d',\n",
       " 'aedd82e4',\n",
       " '445eab21',\n",
       " '41e4d17e',\n",
       " 'f5b8619d',\n",
       " '00d62c1b',\n",
       " '3906de3d',\n",
       " '8d5021e8',\n",
       " '0ca9ddb6',\n",
       " 'd0f5fe59',\n",
       " 'ba97ae07',\n",
       " 'd9fac9be',\n",
       " 'ded97339',\n",
       " 'f8ff0b80',\n",
       " 'dbc1a6ce',\n",
       " '496994bd',\n",
       " 'fcb5c309',\n",
       " 'ff805c23',\n",
       " '5c0a986e',\n",
       " '7f4411dc',\n",
       " '6d75e8bb',\n",
       " 'e76a88a6',\n",
       " '8f2ea7aa',\n",
       " '137eaa0f',\n",
       " '6e82a1ae',\n",
       " 'a5f85a15',\n",
       " '4be741c5',\n",
       " '681b3aeb',\n",
       " '3ac3eb23',\n",
       " '253bf280',\n",
       " '3428a4f5',\n",
       " 'a9f96cdd',\n",
       " '1caeab9d',\n",
       " '3de23699',\n",
       " 'bdad9b1f',\n",
       " '88a62173',\n",
       " 'f8b3ba0a',\n",
       " '88a10436',\n",
       " '7e0986d6',\n",
       " 'd4a91cb9',\n",
       " '913fb3ed',\n",
       " '3631a71a',\n",
       " '95990924',\n",
       " '93b581b8',\n",
       " '9edfc990',\n",
       " 'a65b410d',\n",
       " 'ef135b50',\n",
       " '6e19193c',\n",
       " 'cbded52d',\n",
       " 'ae3edfdc',\n",
       " '4612dd53',\n",
       " 'e48d4e1a',\n",
       " '846bdb03',\n",
       " '2204b7a8',\n",
       " 'e5062a87',\n",
       " '539a4f51',\n",
       " '91413438',\n",
       " 'e8dc4411',\n",
       " 'e40b9e2f',\n",
       " 'd6ad076f',\n",
       " 'b190f7f5',\n",
       " '6cdd2623',\n",
       " 'f9012d9b',\n",
       " 'e21d9049',\n",
       " 'eb5a1d5d',\n",
       " '0a938d79',\n",
       " '82819916',\n",
       " 'a78176bb',\n",
       " '952a094c',\n",
       " '98cf29f8',\n",
       " '776ffc46',\n",
       " '484b58aa',\n",
       " '6d0160f0',\n",
       " '150deff5',\n",
       " 'f15e1fac']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/split_keys.json') as fp:\n",
    "    json_object = json.load(fp)\n",
    "\n",
    "json_object['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c7eb3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphaarc.policy.tokenize import tokenize_task\n",
    "def encode_task(task, tokenizer, model, input_state_max=256, n_examples=10, max_length=256): \n",
    "    tokenized_task = np.array(tokenize_task(task, tokenizer, n_examples, input_state_max, max_length)['input_ids'])\n",
    "    return tokenized_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b5ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def token_stats(logits, ids):\n",
    "    \"\"\"\n",
    "    Given logits   [1, L, V]  and ground-truth ids  [1, L],\n",
    "    return per-token entropy, is_correct flag, and p_true.\n",
    "    \"\"\"\n",
    "    log_p  = torch.log_softmax(logits, -1)           # [1, L, V]\n",
    "    probs  = log_p.exp()\n",
    "\n",
    "    # entropy H_t\n",
    "    entropy = -(probs * log_p).sum(-1).squeeze(0)    # [L]\n",
    "\n",
    "    # probability assigned to the ground-truth token\n",
    "    p_true  = probs.gather(2, ids.unsqueeze(-1)).squeeze(0).squeeze(-1)  # [L]\n",
    "\n",
    "    # was the ground-truth the top-1 token?\n",
    "    p_max, _ = probs.max(-1)\n",
    "    is_correct = (p_true == p_max.squeeze(0)).float()                    # [L]\n",
    "\n",
    "    return entropy.cpu(), is_correct.cpu(), p_true.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ca29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_val_records(val_tasks, tok, model, cache_file=\"entropy_val.pkl\"):\n",
    "    \"\"\"\n",
    "    Returns a list of (entropy, is_error) per token across the whole split.\n",
    "    Uses a cache on disk so you can rerun analyses instantly.\n",
    "    \"\"\"\n",
    "    \"\"\"if Path(cache_file).exists():\n",
    "        return pickle.load(open(cache_file, \"rb\"))\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    records = []      # (entropy, is_error)\n",
    "\n",
    "    for task in tqdm.tqdm(val_tasks, desc=\"val\"):\n",
    "        # --- encode once, as you already do ------------------------------\n",
    "        input_ = torch.tensor(encode_task(task, tok, model)).unsqueeze(0).to(model.device)\n",
    "        ids    = tok(task.program_lines, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_, labels=ids).logits   # [1, L, V]\n",
    "\n",
    "        H, correct, _ = token_stats(logits, ids)\n",
    "        for h, c in zip(H, correct):\n",
    "            records.append((h.item(), int(1 - c.item())))   # is_error = 1 - correct\n",
    "\n",
    "    pickle.dump(records, open(cache_file, \"wb\"))\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c128ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_tau(entropy, is_error, tau):\n",
    "    ent = torch.tensor(entropy)\n",
    "    err = torch.tensor(is_error).bool()\n",
    "    tp  = ((ent > tau) & err).sum()\n",
    "    fn  = ((ent <= tau) & err).sum()\n",
    "    return (tp / (tp + fn + 1e-9)).item()          # avoid 0-div\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bed3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def entropy_reliability(records, recall_target=0.95, tau=0.5):\n",
    "      ent, err = zip(*records)               # lists of floats / ints\n",
    "      ent = torch.tensor(ent)\n",
    "      err = torch.tensor(err)                # 1 = error, 0 = correct\n",
    "\n",
    "      print(f\"Recall @ τ={tau} bits : {recall_at_tau(ent, err, tau):.3f}\")\n",
    "      # ROC-AUC\n",
    "      auc_roc = roc_auc_score(err, ent)\n",
    "      print(f\"ROC-AUC (entropy vs error): {auc_roc:.3f}\")\n",
    "\n",
    "      # Precision-Recall\n",
    "      prec, rec, thr = precision_recall_curve(err, ent)\n",
    "      pr_auc = auc(rec, prec)\n",
    "      print(f\"PR-AUC                         : {pr_auc:.3f}\")\n",
    "\n",
    "      \"\"\"# choose τ to capture recall_target of errors\n",
    "      idx = (rec >= recall_target).nonzero()[0][0]\n",
    "      tau = thr[idx].item()\n",
    "      print(f\"τ at {recall_target:.0%} error recall: {tau:.2f} \"\n",
    "            f\"(precision={prec[idx]:.2f})\")\n",
    "      \"\"\"\n",
    "      from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "      # ------------------------------------------------------------\n",
    "      # inputs you already have\n",
    "      # ------------------------------------------------------------\n",
    "      ent = torch.tensor(ent)        # [N]  entropy per token (or per sequence)\n",
    "      err = torch.tensor(err).bool() # [N]  ground-truth: 1 = error, 0 = correct\n",
    "\n",
    "      # ------------------------------------------------------------\n",
    "      # 1. predicted class from the entropy rule\n",
    "      # ------------------------------------------------------------\n",
    "      pred_err = (ent > tau)         # True ⇒ \"I think it's an error\"\n",
    "\n",
    "      # ------------------------------------------------------------\n",
    "      # 2. overall accuracy\n",
    "      # ------------------------------------------------------------\n",
    "      overall_acc = accuracy_score(err, pred_err)\n",
    "      print(f\"Overall accuracy : {overall_acc:.3f}\")\n",
    "\n",
    "      # ------------------------------------------------------------\n",
    "      # 3. confusion matrix  →  per-class accuracies\n",
    "      # ------------------------------------------------------------\n",
    "      tn, fp, fn, tp = confusion_matrix(err, pred_err).ravel()\n",
    "      print(f\"Correct-class accuracy (specificity) : {tn / (tn+fp):.3f}\")\n",
    "      print(f\"Error-class  accuracy (recall)       : {tp / (tp+fn):.3f}\")\n",
    "\n",
    "      # same numbers—plus precision & F1—in one call:\n",
    "      print(classification_report(err, pred_err,\n",
    "                              target_names=[\"correct\", \"error\"], digits=3))\n",
    "\n",
    "      return tau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb80fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val:   4%|▍         | 4/89 [00:00<00:06, 13.11it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "val: 100%|██████████| 89/89 [00:11<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall @ τ=1 bits : 0.484\n",
      "ROC-AUC (entropy vs error): 0.951\n",
      "PR-AUC                         : 0.733\n",
      "Overall accuracy : 0.915\n",
      "Correct-class accuracy (specificity) : 0.980\n",
      "Error-class  accuracy (recall)       : 0.484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     correct      0.927     0.980     0.953     11383\n",
      "       error      0.783     0.484     0.598      1709\n",
      "\n",
      "    accuracy                          0.915     13092\n",
      "   macro avg      0.855     0.732     0.776     13092\n",
      "weighted avg      0.908     0.915     0.906     13092\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3346980/3237062727.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ent = torch.tensor(entropy)\n",
      "/tmp/ipykernel_3346980/3237062727.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  err = torch.tensor(is_error).bool()\n",
      "/tmp/ipykernel_3346980/1396612188.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ent = torch.tensor(ent)        # [N]  entropy per token (or per sequence)\n",
      "/tmp/ipykernel_3346980/1396612188.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  err = torch.tensor(err).bool() # [N]  ground-truth: 1 = error, 0 = correct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('../finetune-checkpoint/dev-checkpoint')\n",
    "tok = AutoTokenizer.from_pretrained('Salesforce/codet5p-220m')\n",
    "\n",
    "val_tasks = []\n",
    "\n",
    "\n",
    "for file_name in json_object['val']:\n",
    "    task = Task.from_json(f'../data/training/{file_name}.json')\n",
    "    val_tasks.append(task )\n",
    "\n",
    "# 1) gather statistics once\n",
    "records = gather_val_records(val_tasks, tok, model)\n",
    "\n",
    "# 2) measure reliability & pick τ\n",
    "tau = entropy_reliability(records, tau=1 ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaARC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

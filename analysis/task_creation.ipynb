{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0556261a",
   "metadata": {},
   "source": [
    "# Notebook for Generating New Tasks\n",
    "\n",
    "This notebook contains the analysis presented in the chapter related to generating new tasks, please run the compress .py file to generate the jsonl file used in this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4f3a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from alphaarc.task import Task\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json\n",
    "import torch, tqdm, pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from alphaarc.task import Task, from_dict\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import json\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf972b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some loading.\n",
    "\n",
    "import json\n",
    "\n",
    "new_tasks = []\n",
    "with open(\"../data/new_tasks.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        new_tasks.append(json.loads(line))\n",
    "\n",
    "new_tasks = [from_dict(x) for x in new_tasks]\n",
    "\n",
    "\n",
    "with open('../data/split_keys.json') as fp:\n",
    "    json_object = json.load(fp)\n",
    "\n",
    "tasks = []\n",
    "tasks.extend(json_object['train'])\n",
    "tasks.extend(json_object['val'])\n",
    "tasks = [Task.from_json(f\"../data/training/{x}.json\") for x in tasks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dd5347",
   "metadata": {},
   "source": [
    "## Summative Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54249c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num new tasks genearted: 820\n",
      "avg tasks generated: 2.05\n"
     ]
    }
   ],
   "source": [
    "ROOT_TASKS = 400\n",
    "print(f\"num new tasks genearted: {len(new_tasks)}\")\n",
    "print(f\"avg tasks generated: {len(new_tasks) / ROOT_TASKS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b6bf8",
   "metadata": {},
   "source": [
    "## Qualitative Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e66c5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_qualitative_data(): \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaARC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
